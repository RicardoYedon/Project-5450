{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from scipy.sparse.linalg import svds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ratings data\n",
    "ratings = pd.read_csv('ratings_small.csv')\n",
    "\n",
    "# Optional: Load movies data if needed\n",
    "movies = pd.read_csv('movies.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(ratings.isnull().sum())\n",
    "\n",
    "# Since there are no missing values in ratings_small.csv, we can proceed\n",
    "# If there were missing values, we could handle them like this:\n",
    "# ratings['rating'].fillna(ratings['rating'].mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of the dataset\n",
    "print(ratings.head())\n",
    "\n",
    "# Ratings distribution\n",
    "sns.histplot(ratings['rating'], bins=5, kde=False)\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Number of ratings per user\n",
    "ratings_per_user = ratings.groupby('userId')['rating'].count()\n",
    "sns.histplot(ratings_per_user, bins=30, kde=False)\n",
    "plt.title('Number of Ratings per User')\n",
    "plt.xlabel('Number of Ratings')\n",
    "plt.ylabel('Count of Users')\n",
    "plt.show()\n",
    "\n",
    "# Number of ratings per movie\n",
    "ratings_per_movie = ratings.groupby('movieId')['rating'].count()\n",
    "sns.histplot(ratings_per_movie, bins=30, kde=False)\n",
    "plt.title('Number of Ratings per Movie')\n",
    "plt.xlabel('Number of Ratings')\n",
    "plt.ylabel('Count of Movies')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the global mean rating\n",
    "global_mean = ratings['rating'].mean()\n",
    "print(f'Global Mean Rating: {global_mean}')\n",
    "\n",
    "# Create baseline predictions\n",
    "ratings['baseline_pred'] = global_mean\n",
    "\n",
    "# Calculate RMSE for the baseline model\n",
    "baseline_rmse = np.sqrt(mean_squared_error(ratings['rating'], ratings['baseline_pred']))\n",
    "print(f'Baseline RMSE: {baseline_rmse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(ratings, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. K-NN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1 Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pivot table for user-item interactions\n",
    "user_item_matrix = train_data.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "\n",
    "# Fill NaN with zeros for distance calculations\n",
    "user_item_matrix_filled = user_item_matrix.fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.2 Implement K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the NearestNeighbors model\n",
    "knn_model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "knn_model.fit(user_item_matrix_filled)\n",
    "\n",
    "# Function to predict ratings\n",
    "def knn_predict(user_id, movie_id, k=5):\n",
    "    if movie_id not in user_item_matrix_filled.columns:\n",
    "        # Movie not in training data\n",
    "        return global_mean\n",
    "    if user_id not in user_item_matrix_filled.index:\n",
    "        # User not in training data\n",
    "        return global_mean\n",
    "    \n",
    "    distances, indices = knn_model.kneighbors(\n",
    "        user_item_matrix_filled.loc[user_id].values.reshape(1, -1), n_neighbors=k+1)\n",
    "    \n",
    "    similarities = 1 - distances.flatten()\n",
    "    similarities = similarities[1:]  # Exclude the user itself\n",
    "    indices = indices.flatten()[1:]\n",
    "    \n",
    "    neighbor_ratings = user_item_matrix_filled.iloc[indices][movie_id]\n",
    "    mask = neighbor_ratings > 0\n",
    "    if mask.sum() == 0:\n",
    "        return global_mean\n",
    "    predicted_rating = np.dot(similarities[mask], neighbor_ratings[mask]) / similarities[mask].sum()\n",
    "    return predicted_rating\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.3 Evaluate the K-NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict ratings for the test set\n",
    "test_users = test_data['userId'].values\n",
    "test_movies = test_data['movieId'].values\n",
    "knn_predictions = []\n",
    "\n",
    "for user, movie in zip(test_users, test_movies):\n",
    "    pred = knn_predict(user, movie, k=5)\n",
    "    knn_predictions.append(pred)\n",
    "\n",
    "# Calculate RMSE\n",
    "knn_rmse = np.sqrt(mean_squared_error(test_data['rating'], knn_predictions))\n",
    "print(f'K-NN Model RMSE: {knn_rmse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. SVD Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.1 Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a user-item rating matrix\n",
    "R = train_data.pivot_table(index='userId', columns='movieId', values='rating').fillna(0).values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.2 Compute SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean center the data\n",
    "R_mean = np.mean(R, axis=1)\n",
    "R_demeaned = R - R_mean.reshape(-1, 1)\n",
    "\n",
    "# Perform SVD\n",
    "U, sigma, Vt = svds(R_demeaned, k=50)  # Choose k latent factors\n",
    "sigma = np.diag(sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.3 Reconstruct the Ratings Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the approximated ratings matrix\n",
    "R_pred = np.dot(np.dot(U, sigma), Vt) + R_mean.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.4 Evaluate the SVD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the reconstructed matrix back to DataFrame\n",
    "predictions_df = pd.DataFrame(R_pred, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "\n",
    "def svd_predict(user_id, movie_id):\n",
    "    try:\n",
    "        return predictions_df.loc[user_id, movie_id]\n",
    "    except:\n",
    "        return global_mean\n",
    "\n",
    "# Predict ratings for the test set\n",
    "svd_predictions = []\n",
    "\n",
    "for user, movie in zip(test_users, test_movies):\n",
    "    pred = svd_predict(user, movie)\n",
    "    svd_predictions.append(pred)\n",
    "\n",
    "# Calculate RMSE\n",
    "svd_rmse = np.sqrt(mean_squared_error(test_data['rating'], svd_predictions))\n",
    "print(f'SVD Model RMSE: {svd_rmse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Cross-Validation and Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.1 Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll perform 5-fold cross-validation on both models.\n",
    "\n",
    "K-NN Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "knn_rmse_scores = []\n",
    "\n",
    "for train_indices, test_indices in kf.split(ratings):\n",
    "    train_cv = ratings.iloc[train_indices]\n",
    "    test_cv = ratings.iloc[test_indices]\n",
    "    \n",
    "    # Prepare user-item matrix\n",
    "    user_item_matrix_cv = train_cv.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "    user_item_matrix_filled_cv = user_item_matrix_cv.fillna(0)\n",
    "    \n",
    "    # Fit K-NN model\n",
    "    knn_model_cv = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "    knn_model_cv.fit(user_item_matrix_filled_cv)\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    test_users_cv = test_cv['userId'].values\n",
    "    test_movies_cv = test_cv['movieId'].values\n",
    "    knn_predictions_cv = []\n",
    "    \n",
    "    for user, movie in zip(test_users_cv, test_movies_cv):\n",
    "        pred = knn_predict(user, movie, k=5)\n",
    "        knn_predictions_cv.append(pred)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(test_cv['rating'], knn_predictions_cv))\n",
    "    knn_rmse_scores.append(rmse)\n",
    "\n",
    "print(f'K-NN Cross-Validation RMSE: {np.mean(knn_rmse_scores)} ± {np.std(knn_rmse_scores)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_rmse_scores = []\n",
    "\n",
    "for train_indices, test_indices in kf.split(ratings):\n",
    "    train_cv = ratings.iloc[train_indices]\n",
    "    test_cv = ratings.iloc[test_indices]\n",
    "    \n",
    "    # Prepare user-item matrix\n",
    "    R_cv = train_cv.pivot_table(index='userId', columns='movieId', values='rating').fillna(0).values\n",
    "    \n",
    "    # Mean center the data\n",
    "    R_mean_cv = np.mean(R_cv, axis=1)\n",
    "    R_demeaned_cv = R_cv - R_mean_cv.reshape(-1, 1)\n",
    "    \n",
    "    # Perform SVD\n",
    "    U_cv, sigma_cv, Vt_cv = svds(R_demeaned_cv, k=50)\n",
    "    sigma_cv = np.diag(sigma_cv)\n",
    "    \n",
    "    # Reconstruct the ratings matrix\n",
    "    R_pred_cv = np.dot(np.dot(U_cv, sigma_cv), Vt_cv) + R_mean_cv.reshape(-1, 1)\n",
    "    predictions_df_cv = pd.DataFrame(R_pred_cv, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    svd_predictions_cv = []\n",
    "    \n",
    "    for user, movie in zip(test_cv['userId'], test_cv['movieId']):\n",
    "        pred = predictions_df_cv.loc[user, movie] if movie in predictions_df_cv.columns else global_mean\n",
    "        svd_predictions_cv.append(pred)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(test_cv['rating'], svd_predictions_cv))\n",
    "    svd_rmse_scores.append(rmse)\n",
    "\n",
    "print(f'SVD Cross-Validation RMSE: {np.mean(svd_rmse_scores)} ± {np.std(svd_rmse_scores)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.2 Hypothesis Testing\n",
    "We will perform a paired t-test to see if the advanced models significantly outperform the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Baseline predictions on test set\n",
    "baseline_predictions = np.full(len(test_data), global_mean)\n",
    "\n",
    "# Calculate errors\n",
    "baseline_errors = (test_data['rating'] - baseline_predictions) ** 2\n",
    "knn_errors = (test_data['rating'] - knn_predictions) ** 2\n",
    "svd_errors = (test_data['rating'] - svd_predictions) ** 2\n",
    "\n",
    "# Paired t-test between baseline and K-NN\n",
    "t_stat_knn, p_value_knn = ttest_rel(baseline_errors, knn_errors)\n",
    "print(f'K-NN vs Baseline t-statistic: {t_stat_knn}, p-value: {p_value_knn}')\n",
    "\n",
    "# Paired t-test between baseline and SVD\n",
    "t_stat_svd, p_value_svd = ttest_rel(baseline_errors, svd_errors)\n",
    "print(f'SVD vs Baseline t-statistic: {t_stat_svd}, p-value: {p_value_svd}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "Null Hypothesis: There is no significant difference between the model's RMSE and the baseline RMSE.\n",
    "Alternative Hypothesis: The model's RMSE is significantly lower than the baseline RMSE.\n",
    "If the p-value is less than 0.05, we reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Hybrid Recommendation System\n",
    "When user data is limited, we'll recommend:\n",
    "\n",
    "3 most popular movies\n",
    "2 personalized recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.1 Most Popular Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 3 most rated movies\n",
    "popular_movies = ratings.groupby('movieId').size().sort_values(ascending=False).head(3).index.tolist()\n",
    "\n",
    "# Map movie IDs to titles\n",
    "popular_movie_titles = movies[movies['movieId'].isin(popular_movies)]['title'].tolist()\n",
    "print('Top 3 Popular Movies:')\n",
    "for title in popular_movie_titles:\n",
    "    print(title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.2 Personalized Recommendations\n",
    "Assuming we have a new user with limited data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_recommendations(user_id, k=5):\n",
    "    # If user is new, recommend popular movies\n",
    "    if user_id not in user_item_matrix.index:\n",
    "        return popular_movie_titles\n",
    "    \n",
    "    # Get personalized recommendations\n",
    "    user_predictions = predictions_df.loc[user_id].sort_values(ascending=False)\n",
    "    recommended_movie_ids = user_predictions.index[:k]\n",
    "    recommended_movies = movies[movies['movieId'].isin(recommended_movie_ids)]['title'].tolist()\n",
    "    return recommended_movies\n",
    "\n",
    "# Example usage:\n",
    "new_user_id = 9999  # New user ID\n",
    "recommendations = hybrid_recommendations(new_user_id)\n",
    "print('Recommendations for New User:')\n",
    "for rec in recommendations:\n",
    "    print(rec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Analysis\n",
    "Compare the performance of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Baseline RMSE: {baseline_rmse}')\n",
    "print(f'K-NN Model RMSE: {knn_rmse}')\n",
    "print(f'SVD Model RMSE: {svd_rmse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: Check which model has the lowest RMSE.\n",
    "Conclusion: Determine if the advanced models significantly outperform the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Conclusion\n",
    "We have:\n",
    "\n",
    "Implemented a baseline model and two advanced models (K-NN and SVD).\n",
    "Evaluated their performance using RMSE.\n",
    "Performed hypothesis testing to validate our models.\n",
    "Built a hybrid recommendation system for users with limited data.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
